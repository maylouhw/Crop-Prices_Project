{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45f3177-1643-4b71-aa5d-3c520b28e72f",
   "metadata": {},
   "source": [
    "**CROP PRICES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53b5d6-751e-499d-bb64-aaf99ded5bdf",
   "metadata": {},
   "source": [
    "**1. Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e57d2-94df-42a7-b015-e160ccbbf121",
   "metadata": {},
   "source": [
    "The price of avocados fluctuates due to various factors such as demand, supply, seasonality, and regional differences. Accurately predicting avocado prices can help farmers, retailers, and consumers make informed decisions. This project aims to develop a machine learning model that forecasts avocado prices based on historical sales data and market trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c314148-4430-4aab-8096-988f491d014e",
   "metadata": {},
   "source": [
    "**2. Project Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c53e84-c36a-4717-b3aa-fa587db8e4cd",
   "metadata": {},
   "source": [
    "1. Analyze historical avocado sales and pricing trends.\n",
    "\n",
    "2. Identify key factors influencing price fluctuations.\n",
    "\n",
    "3. Build a predictive model to forecast avocado prices.\n",
    "\n",
    "4. Deploy the model in a user-friendly interface for real-time price predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b55358-5426-49d8-832a-754339dfe023",
   "metadata": {},
   "source": [
    "**3. Data Sources**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269d679-177b-4c12-a8e9-72e15490dd38",
   "metadata": {},
   "source": [
    "1. Hass Avocado Board: Provides historical avocado price and sales data.\n",
    "\n",
    "2. Kaggle Datasets: Public datasets on avocado prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e6e53-05fe-4068-905d-d479c2283cd5",
   "metadata": {},
   "source": [
    "**4. Success Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042347fb-f87f-4885-8f9e-e2e85b0ad2e9",
   "metadata": {},
   "source": [
    "__To evaluate the effectiveness of the model, we will use:__\n",
    "\n",
    "   *Mean Absolute Error (MAE): Measures prediction accuracy.\n",
    "\n",
    "   *Root Mean Squared Error (RMSE): To penalize large prediction errors.\n",
    "\n",
    "   *R² Score: To assess how well features explain the variance in price.\n",
    "\n",
    "   *Model Deployment Readiness: The model should be lightweight and efficient for real-time predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e5edd-4571-45cb-8e2f-64c500dbbe16",
   "metadata": {},
   "source": [
    "**DATA COLLECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4401a1f-f12e-4d1b-9017-8566bfb56b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.10-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fransisca nong\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\fransisca nong\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.10-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.0/63.0 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21e74a7-f58e-40b6-8b6a-63e23c77a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/vakhariapujan/avocado-prices-and-sales-volume-2015-2023?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.68M/1.68M [00:04<00:00, 421kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\Fransisca Nong\\.cache\\kagglehub\\datasets\\vakhariapujan\\avocado-prices-and-sales-volume-2015-2023\\versions\\3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vakhariapujan/avocado-prices-and-sales-volume-2015-2023\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b37d7f-9b42-4eec-b861-499f334fe1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53415 entries, 0 to 53414\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date          53415 non-null  object \n",
      " 1   AveragePrice  53415 non-null  float64\n",
      " 2   TotalVolume   53415 non-null  float64\n",
      " 3   plu4046       53415 non-null  float64\n",
      " 4   plu4225       53415 non-null  float64\n",
      " 5   plu4770       53415 non-null  float64\n",
      " 6   TotalBags     53415 non-null  float64\n",
      " 7   SmallBags     41025 non-null  float64\n",
      " 8   LargeBags     41025 non-null  float64\n",
      " 9   XLargeBags    41025 non-null  float64\n",
      " 10  type          53415 non-null  object \n",
      " 11  region        53415 non-null  object \n",
      "dtypes: float64(9), object(3)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "         Date  AveragePrice  TotalVolume    plu4046    plu4225   plu4770  \\\n",
      "0  2015-01-04          1.22     40873.28    2819.50   28287.42     49.90   \n",
      "1  2015-01-04          1.79      1373.95      57.42     153.88      0.00   \n",
      "2  2015-01-04          1.00    435021.49  364302.39   23821.16     82.15   \n",
      "3  2015-01-04          1.76      3846.69    1500.15     938.35      0.00   \n",
      "4  2015-01-04          1.08    788025.06   53987.31  552906.04  39995.03   \n",
      "\n",
      "   TotalBags  SmallBags  LargeBags  XLargeBags          type  \\\n",
      "0    9716.46    9186.93     529.53         0.0  conventional   \n",
      "1    1162.65    1162.65       0.00         0.0       organic   \n",
      "2   46815.79   16707.15   30108.64         0.0  conventional   \n",
      "3    1408.19    1071.35     336.84         0.0       organic   \n",
      "4  141136.68  137146.07    3990.61         0.0  conventional   \n",
      "\n",
      "                region  \n",
      "0               Albany  \n",
      "1               Albany  \n",
      "2              Atlanta  \n",
      "3              Atlanta  \n",
      "4  BaltimoreWashington  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# file path\n",
    "file_path = r\"C:\\Users\\Fransisca Nong\\Downloads\\archive (1)\\Avocado_HassAvocadoBoard_20152023v1.0.1.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display dataset info and first few rows\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64aa04e-b1ac-46bc-9460-225c947ec24e",
   "metadata": {},
   "source": [
    "**CHECKING FOR DUPLICATES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcf8b6cf-8677-4138-a64f-fa692a2264b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f\"Number of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c089c-fe1c-4779-8149-90329646f949",
   "metadata": {},
   "source": [
    "**CHECKING FOR MISSING VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a950bc57-4cae-4b19-95f0-83fe554521ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " Date                0\n",
      "AveragePrice        0\n",
      "TotalVolume         0\n",
      "plu4046             0\n",
      "plu4225             0\n",
      "plu4770             0\n",
      "TotalBags           0\n",
      "SmallBags       12390\n",
      "LargeBags       12390\n",
      "XLargeBags      12390\n",
      "type                0\n",
      "region              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23faefa0-056d-4c6d-b680-2a5e8b1c450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values:\n",
      " SmallBags     23.195732\n",
      "LargeBags     23.195732\n",
      "XLargeBags    23.195732\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percent = df[[\"SmallBags\", \"LargeBags\", \"XLargeBags\"]].isnull().sum() / len(df) * 100\n",
    "print(\"Percentage of missing values:\\n\", missing_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be1bfd7c-cd01-450a-af01-a178ab4591ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing by type:\n",
      " type\n",
      "conventional    6195\n",
      "organic         6195\n",
      "Name: count, dtype: int64\n",
      "Missing by region:\n",
      " region\n",
      "Albany                  210\n",
      "SanDiego                210\n",
      "Orlando                 210\n",
      "PeoriaSpringfield       210\n",
      "Philadelphia            210\n",
      "PhoenixTucson           210\n",
      "Pittsburgh              210\n",
      "Plains                  210\n",
      "Portland                210\n",
      "Providence              210\n",
      "RaleighGreensboro       210\n",
      "RichmondNorfolk         210\n",
      "Roanoke                 210\n",
      "Sacramento              210\n",
      "SanFrancisco            210\n",
      "Northeast               210\n",
      "Seattle                 210\n",
      "SouthCarolina           210\n",
      "SouthCentral            210\n",
      "Southeast               210\n",
      "Spokane                 210\n",
      "StLouis                 210\n",
      "Syracuse                210\n",
      "Tampa                   210\n",
      "Toledo                  210\n",
      "TotalUS                 210\n",
      "West                    210\n",
      "WestTexNewMexico        210\n",
      "NorthernNewEngland      210\n",
      "NewYork                 210\n",
      "Atlanta                 210\n",
      "Detroit                 210\n",
      "BaltimoreWashington     210\n",
      "BirminghamMontgomery    210\n",
      "Boise                   210\n",
      "Boston                  210\n",
      "BuffaloRochester        210\n",
      "California              210\n",
      "Charlotte               210\n",
      "Chicago                 210\n",
      "CincinnatiDayton        210\n",
      "Columbus                210\n",
      "DallasFtWorth           210\n",
      "Denver                  210\n",
      "GrandRapids             210\n",
      "NewOrleans              210\n",
      "GreatLakes              210\n",
      "HarrisburgScranton      210\n",
      "HartfordSpringfield     210\n",
      "Houston                 210\n",
      "Indianapolis            210\n",
      "Jacksonville            210\n",
      "LasVegas                210\n",
      "LosAngeles              210\n",
      "Louisville              210\n",
      "MiamiFtLauderdale       210\n",
      "Midsouth                210\n",
      "Nashville               210\n",
      "Wichita                 210\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if missing values are related to type or region\n",
    "missing_rows = df[df[[\"SmallBags\", \"LargeBags\", \"XLargeBags\"]].isnull().any(axis=1)]\n",
    "missing_by_type = missing_rows[\"type\"].value_counts()\n",
    "missing_by_region = missing_rows[\"region\"].value_counts()\n",
    "\n",
    "print(\"Missing by type:\\n\", missing_by_type)\n",
    "print(\"Missing by region:\\n\", missing_by_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "963a8b77-d96a-4a17-928f-ac4800898cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmallBags     0\n",
      "LargeBags     0\n",
      "XLargeBags    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the median for each column\n",
    "df[\"SmallBags\"] = df[\"SmallBags\"].fillna(df[\"SmallBags\"].median())\n",
    "df[\"LargeBags\"] = df[\"LargeBags\"].fillna(df[\"LargeBags\"].median())\n",
    "df[\"XLargeBags\"] = df[\"XLargeBags\"].fillna(df[\"XLargeBags\"].median())\n",
    "\n",
    "# handled missing values\n",
    "print(df[[\"SmallBags\", \"LargeBags\", \"XLargeBags\"]].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a6e31-1d67-4110-81c1-70b127ca228a",
   "metadata": {},
   "source": [
    "**Encode Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7f34d36-7fc4-49d9-8ddf-1d6ef3cf4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"type\", \"region\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c481fdd-7492-4afc-a216-5141d23eb792",
   "metadata": {},
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d55cfc9-27db-4da4-a97d-8d815b83b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[['TotalVolume', 'plu4046', 'plu4225', 'plu4770', 'TotalBags', 'SmallBags', 'LargeBags', 'XLargeBags', 'AveragePrice']] = scaler.fit_transform(\n",
    "    df[['TotalVolume', 'plu4046', 'plu4225', 'plu4770', 'TotalBags', 'SmallBags', 'LargeBags', 'XLargeBags', 'AveragePrice']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6ff0693-68da-43c6-b660-af6c7a4820c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers per column:\n",
      " AveragePrice      358\n",
      "TotalVolume      6484\n",
      "plu4046          7263\n",
      "plu4225          8193\n",
      "plu4770          9375\n",
      "TotalBags        6845\n",
      "SmallBags       10080\n",
      "LargeBags       11130\n",
      "XLargeBags       8397\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get a list of numeric columns\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "\n",
    "Q1 = df[numeric_columns].quantile(0.25)\n",
    "Q3 = df[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers\n",
    "outliers = ((df[numeric_columns] < (Q1 - 1.5 * IQR)) | (df[numeric_columns] > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "# Check the number of outliers\n",
    "outlier_counts = outliers.sum()\n",
    "print(\"Outliers per column:\\n\", outlier_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58687abb-340f-4476-a895-e24400523997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
